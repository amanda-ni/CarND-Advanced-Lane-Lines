{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to Detect Lanes\n",
    "---\n",
    "\n",
    "## Calibrate Camera\n",
    "\n",
    "This step needs to only be done once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from lane_functions import chessboard_corners, find_reclanes, draw_box, window_mask, find_sliding_poly, draw_lane\n",
    "\n",
    "from IPython.display import Image, HTML, display\n",
    "from glob import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and Cal Data\n",
    "\n",
    "These include:\n",
    "- Checkerboard dimensions\n",
    "  + This took me an especially long time to debug. It turns out, I had\n",
    "    miscounted the number of corners for each of the checkerboards.\n",
    "    The count in the original lab example had (8,5). In contrast, the\n",
    "    checkerboards here have (9,6) corners.\n",
    "- Input file directory with images\n",
    "  + This is found in `camera_cal/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to find the chessboard corners. We have 9 columns and 6 rows, stored in \"camera_cal\"\n",
    "checkcols = 9\n",
    "checkrows = 6\n",
    "imdir = 'camera_cal/'\n",
    "\n",
    "# Find the object points and correspond with image points\n",
    "objpoints, imgpoints = chessboard_corners( imdir, checkcols, checkrows )\n",
    "\n",
    "# Visualize the images\n",
    "imagesList=''.join( [\"<img style='width: 150px; margin: 0px; float: left; border: 1px solid black;' src='%s' />\" % str(s) \n",
    "                 for s in sorted(glob('examples/calibration_output/*.jpg')) ])\n",
    "display(HTML(imagesList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Parameters to Undistort\n",
    "\n",
    "Make calls to calibrate the camera. The calibration and distortion parameters are stored in `mtx` and `dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test undistortion on an image\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "print('Length Objects: {}, Image Points: {}'.format(len(objpoints), len(imgpoints)))\n",
    "print('Image Size: {}'.format(img_size))\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10)); \n",
    "ax1.axis('off'); ax2.axis('off')\n",
    "ax1.imshow(img); plt.imsave('examples/distorted.jpg',img); \n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst); plt.imsave('examples/undistorted.jpg', dst); \n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reprojection Parameters (Perspective)\n",
    "\n",
    "Warp the image to an overhead perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format is:\n",
    "#    [ UpperLeft, LowerLeft, LowerRight, UpperRight ]\n",
    "#    Assuming some symmetry, I added equal numbers left and right\n",
    "src = np.float32(\n",
    "     [[img_size[0] / 2 - 64, img_size[1] / 2 + 100],\n",
    "      [img_size[0] / 6 - 10, img_size[1]],\n",
    "      [img_size[0] * 5 / 6 + 10, img_size[1]],\n",
    "      [img_size[0] / 2 + 64, img_size[1] / 2 + 100]])\n",
    "dst = np.float32(\n",
    "    [[(img_size[0] / 4) + 50, 0],\n",
    "     [(img_size[0] / 4) + 50, img_size[1]],\n",
    "     [(img_size[0] * 3 / 4) - 50, img_size[1]],\n",
    "     [(img_size[0] * 3 / 4) - 50, 0]])\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst,src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_images/test2.jpg')\n",
    "# img = cv2.imread('test_images/straight_lines2.jpg')\n",
    "calimg = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "warped = cv2.warpPerspective(calimg, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,10))\n",
    "ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "ax1.set_title('Original Image', fontsize=30); ax1.axis('off')\n",
    "ax2.imshow(cv2.cvtColor(calimg, cv2.COLOR_BGR2RGB))\n",
    "ax2.set_title('Undistorted Image', fontsize=30); ax2.axis('off')\n",
    "ax3.imshow(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB))\n",
    "ax3.set_title('Warped Image', fontsize=30); ax3.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw lines on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcpairs = []; dstpairs = []\n",
    "for pair in src:\n",
    "    srcpairs += [tuple(pair.astype(int))]\n",
    "for pair in dst:\n",
    "    dstpairs += [tuple(pair.astype(int))]\n",
    "    \n",
    "fig = plt.figure(figsize=(40,40)); plt.axis('on'); fig.subplots(1,3)\n",
    "ax1 = plt.subplot(1,3,1); ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "ax1.set_title('Original Image', fontsize=30); \n",
    "ax2 = plt.subplot(1,3,2); draw_box(calimg, srcpairs)\n",
    "ax2.set_title('Undistorted Image', fontsize=30); \n",
    "ax3 = plt.subplot(1,3,3); draw_box(warped, dstpairs)\n",
    "ax3.set_title('Warped Image', fontsize=30); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some line detection from the overhead imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_binary, combined_binary = find_reclanes(warped)\n",
    "\n",
    "# Plotting thresholded images\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.set_title('Stacked thresholds')\n",
    "ax1.imshow(color_binary)\n",
    "\n",
    "ax2.set_title('Combined S channel and gradient thresholds')\n",
    "ax2.imshow(combined_binary, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_fit, right_fit = find_sliding_poly(combined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_warped = combined_binary\n",
    "\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "# out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "# out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "# plt.imshow(out_img)\n",
    "plt.imshow(binary_warped)\n",
    "plt.plot(left_fitx, ploty, color='red')\n",
    "plt.plot(right_fitx, ploty, color='red')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image to draw the lines on\n",
    "warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "\n",
    "# color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "color_warp = np.copy(warp_zero)\n",
    "\n",
    "# # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "# Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "# Combine the result with the original image\n",
    "result = cv2.addWeighted(calimg, 1, newwarp, 0.3, 0)\n",
    "plt.imshow(cv2.cvtColor(result,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lanes(imname, mtx, dist, M, Minv):\n",
    "    '''\n",
    "    Draw lanes on top of image given distortion and image warping matrix\n",
    "    Arguments:\n",
    "      imname - image name (text)\n",
    "      mtx - camera calibration coefficient\n",
    "      dist - distortion coefficient\n",
    "      M - warping matrix\n",
    "      Minv = inverse of warping matrix\n",
    "      \n",
    "    Returns:\n",
    "      image with lanes overlayed on top\n",
    "    '''\n",
    "    if type(imname) == str:\n",
    "        img = cv2.imread(imname)\n",
    "    else:\n",
    "        img = imname\n",
    "    calimg = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    warped = cv2.warpPerspective(calimg, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    color_binary, combined_binary = find_reclanes(warped)\n",
    "    left_fit, right_fit = find_sliding_poly(combined_binary)\n",
    "    lanedrawn = draw_lane(left_fit, right_fit, img_size=img_size)\n",
    "    newwarp = cv2.warpPerspective(lanedrawn, Minv, (img.shape[1], img.shape[0]))     \n",
    "    return cv2.addWeighted(calimg, 1, newwarp, 0.3, 0)\n",
    "\n",
    "laneimage = detect_lanes('test_images/test1.jpg', mtx, dist, M, Minv)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(laneimage,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Create a decorator function that will process a single frame with known calibration and warp parameters\n",
    "def detect_lanes_video(img):\n",
    "    return detect_lanes(img, mtx, dist, M, Minv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "video_output1 = 'output_videos/challenge_video_output.mp4'\n",
    "video_input1 = VideoFileClip('input_videos/challenge_video.mp4')#.subclip(22,26)\n",
    "processed_video = video_input1.fl_image(detect_lanes_video)\n",
    "%time processed_video.write_videofile(video_output1, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
